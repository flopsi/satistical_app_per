"""
Statistical Data Analysis Platform - Streamlit App
Complete 6-Phase Workflow with Hierarchical Sales Analysis

Features:
- Account-level hierarchy (top level)
- Project-level aggregation (aggregates all prices by project)
- Multi-filter system
- Drill-down analysis

To run locally:
    pip install -r requirements.txt
    streamlit run streamlit_complete_app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import io
import warnings
from typing import Dict, Tuple
from datetime import datetime

warnings.filterwarnings('ignore')

# Page Configuration
st.set_page_config(
    page_title="Statistical Analysis Platform",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
    .filter-box {
        background: #e8f4f8;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .hierarchy-header {
        background: linear-gradient(90deg, #1f77b4 0%, #4dabf7 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        font-size: 1.2rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}
if 'filtered_data' not in st.session_state:
    st.session_state.filtered_data = None
if 'aggregated_data' not in st.session_state:
    st.session_state.aggregated_data = None

# ============================================================================
# DATA LOADING CLASSES
# ============================================================================

class DataLoader:
    """Handle data loading from multiple sources."""

    def __init__(self):
        self.df = None
        self.metadata = {}

    def load_from_upload(self, uploaded_file) -> Tuple[pd.DataFrame, Dict]:
        """Load data from Streamlit file uploader with enhanced parsing."""
        try:
            if uploaded_file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except:
                    uploaded_file.seek(0)
                    try:
                        df = pd.read_csv(uploaded_file, encoding='latin-1')
                    except:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding='utf-8', sep=None, engine='python')
            elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(uploaded_file, sheet_name=0)
            elif uploaded_file.name.endswith('.json'):
                df = pd.read_json(uploaded_file)
            elif uploaded_file.name.endswith('.parquet'):
                df = pd.read_parquet(uploaded_file)
            elif uploaded_file.name.endswith('.tsv'):
                df = pd.read_csv(uploaded_file, sep='\t')
            else:
                st.error(f"Unsupported file type: {uploaded_file.name}")
                return None, None

            df.columns = df.columns.astype(str).str.strip()

            for col in df.select_dtypes(include=['object']).columns:
                try:
                    df[col] = pd.to_numeric(df[col], errors='ignore')
                except:
                    pass

            self.df = df
            self.metadata = {
                'source': 'upload',
                'filename': uploaded_file.name,
                'rows': len(df),
                'columns': len(df.columns)
            }
            return df, self.metadata
        except Exception as e:
            st.error(f"Error loading file: {e}")
            return None, None


# ============================================================================
# AGGREGATION ENGINE
# ============================================================================

class HierarchicalAggregator:
    """Handle hierarchical data aggregation."""

    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.project_agg = None
        self.account_agg = None

    def aggregate_by_project(self, price_col='Total Price', project_col='SFDC Project No.') -> pd.DataFrame:
        """Aggregate all prices by project number."""
        if price_col not in self.df.columns or project_col not in self.df.columns:
            return None

        # Group by project and sum prices
        agg_dict = {price_col: 'sum'}

        # Include other relevant columns (take first value)
        other_cols = [col for col in self.df.columns if col not in [project_col, price_col]]
        for col in other_cols:
            agg_dict[col] = 'first'

        self.project_agg = self.df.groupby(project_col).agg(agg_dict).reset_index()
        return self.project_agg

    def aggregate_by_account(self, price_col='Total Price', account_col='Accounts Name') -> pd.DataFrame:
        """Aggregate by account (top-level hierarchy)."""
        if self.project_agg is None:
            return None

        if account_col not in self.project_agg.columns:
            return None

        # Aggregate to account level
        self.account_agg = self.project_agg.groupby(account_col).agg({
            price_col: ['sum', 'mean', 'count'],
            'SFDC Project No.': 'count'
        }).reset_index()

        self.account_agg.columns = [account_col, 'Total_Revenue', 'Avg_Project_Value', 
                                    'Num_Prices', 'Num_Projects']

        return self.account_agg

    def get_account_drill_down(self, account_name: str) -> pd.DataFrame:
        """Get all projects for a specific account."""
        if self.project_agg is None:
            return None

        account_col = 'Accounts Name' if 'Accounts Name' in self.project_agg.columns else self.project_agg.columns[1]
        return self.project_agg[self.project_agg[account_col] == account_name]


# ============================================================================
# ANALYSIS CLASSES
# ============================================================================

class QualityAssessment:
    """Data quality assessment."""

    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.report = {}

    def assess(self) -> Dict:
        """Generate quality report."""
        missing_pct = (self.df.isna().sum().sum()) / (len(self.df) * len(self.df.columns))
        completeness = 1.0 - missing_pct
        duplicate_rows = len(self.df[self.df.duplicated()])
        uniqueness = 1.0 - (duplicate_rows / len(self.df)) if len(self.df) > 0 else 1.0

        self.report = {
            'completeness': round(completeness, 3),
            'uniqueness': round(uniqueness, 3),
            'overall': round((completeness + uniqueness) / 2, 3),
            'duplicates': int(duplicate_rows),
            'missing_cells': int(self.df.isna().sum().sum())
        }
        return self.report


class EnhancedProfiler:
    """Comprehensive data profiling."""

    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.profiles = {}

    def profile_numeric(self, series: pd.Series) -> Dict:
        """Profile numeric column."""
        data = series.dropna()
        if len(data) == 0:
            return {'error': 'All values missing'}

        return {
            'type': 'numeric',
            'count': len(series),
            'missing': int(series.isna().sum()),
            'mean': round(float(data.mean()), 4),
            'median': round(float(data.median()), 4),
            'std': round(float(data.std()), 4),
            'min': round(float(data.min()), 4),
            'max': round(float(data.max()), 4),
            'skewness': round(float(data.skew()), 4)
        }

    def auto_profile(self) -> Dict:
        """Profile all columns."""
        for col in self.df.columns:
            if pd.api.types.is_numeric_dtype(self.df[col]):
                self.profiles[col] = self.profile_numeric(self.df[col])
        return self.profiles


class CorrelationEngine:
    """Correlation analysis."""

    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.pearson_corr = None

    def pearson_matrix(self) -> pd.DataFrame:
        """Calculate Pearson correlation."""
        numeric_df = self.df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            return None
        self.pearson_corr = numeric_df.corr(method='pearson')
        return self.pearson_corr

    def create_heatmap(self):
        """Create correlation heatmap."""
        if self.pearson_corr is None:
            self.pearson_matrix()

        if self.pearson_corr is None:
            return None

        fig = go.Figure(data=go.Heatmap(
            z=self.pearson_corr.values,
            x=self.pearson_corr.columns,
            y=self.pearson_corr.columns,
            colorscale='RdBu',
            zmid=0,
            text=np.round(self.pearson_corr.values, 2),
            texttemplate='%{text:.2f}'
        ))

        fig.update_layout(
            title="Correlation Heatmap",
            width=700,
            height=600
        )
        return fig


class DistributionAnalyzer:
    """Distribution analysis and normality testing."""

    def __init__(self, df: pd.DataFrame):
        self.df = df

    def test_normality(self, series: pd.Series) -> Dict:
        """Test for normality."""
        data = series.dropna()
        if len(data) < 3:
            return {'error': 'insufficient_data'}

        shapiro_stat, shapiro_p = stats.shapiro(data)

        return {
            'shapiro_wilk_p': round(float(shapiro_p), 4),
            'shapiro_wilk_stat': round(float(shapiro_stat), 4),
            'interpretation': 'Normal' if shapiro_p > 0.05 else 'Non-normal'
        }

    def create_histogram(self, series: pd.Series):
        """Create histogram with KDE."""
        fig = px.histogram(series, nbins=30, title=f'Distribution: {series.name}')
        return fig


class OutlierAnalyzer:
    """Outlier detection."""

    def __init__(self, df: pd.DataFrame):
        self.df = df

    def detect_iqr(self, series: pd.Series) -> Dict:
        """Detect outliers using IQR."""
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outlier_mask = (series < lower_bound) | (series > upper_bound)
        outliers = series[outlier_mask]

        return {
            'count': int(len(outliers)),
            'percentage': round((len(outliers) / len(series)) * 100, 2),
            'bounds': {'lower': float(lower_bound), 'upper': float(upper_bound)}
        }

# ============================================================================
# STREAMLIT UI
# ============================================================================

# Header
st.markdown('<h1 class="main-header">üìä Statistical Analysis Platform</h1>', unsafe_allow_html=True)
st.markdown("### Hierarchical Sales Analysis with Account > Project Aggregation")
st.markdown("---")

# Sidebar Navigation
st.sidebar.title("üìä Navigation")
phase = st.sidebar.radio(
    "Select Phase:",
    [
        "üè† Home",
        "üì• Phase 1: Data Ingestion",
        "üè¢ Phase 2: Hierarchical Analysis",
        "üîç Phase 3: Advanced Filtering",
        "üî¨ Phase 4: Statistical Testing",
        "üìà Phase 5: Visualization",
        "üìÑ Phase 6: Reporting"
    ]
)

st.sidebar.markdown("---")
if st.session_state.data is not None:
    st.sidebar.success(f"‚úÖ Data loaded: {len(st.session_state.data)} rows")
    if st.session_state.aggregated_data is not None:
        st.sidebar.info(f"üìä Aggregated: {len(st.session_state.aggregated_data)} accounts")

# ============================================================================
# HOME
# ============================================================================

if phase == "üè† Home":
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Phases", "6", "Complete")
    with col2:
        st.metric("Hierarchy Levels", "2", "Account > Project")
    with col3:
        st.metric("Aggregation", "Auto", "By Project")
    with col4:
        st.metric("Filters", "Multi-Select", "All Columns")

    st.markdown("---")
    st.markdown("### üéØ Hierarchical Analysis Structure")

    st.markdown("""
    ```
    üìä Account (Top Level)
    ‚îú‚îÄ‚îÄ Total Revenue (sum of all projects)
    ‚îú‚îÄ‚îÄ Average Project Value
    ‚îú‚îÄ‚îÄ Number of Projects
    ‚îî‚îÄ‚îÄ üìÅ Projects (Aggregated Level)
        ‚îú‚îÄ‚îÄ Project Total (sum of all prices for that project)
        ‚îú‚îÄ‚îÄ Product Line
        ‚îú‚îÄ‚îÄ Stage
        ‚îú‚îÄ‚îÄ Account Manager
        ‚îî‚îÄ‚îÄ Close Year
    ```
    """)

    st.markdown("---")
    st.markdown("### üí° Analysis Flow")

    workflow_df = pd.DataFrame({
        'Phase': ['1Ô∏è‚É£ Ingestion', '2Ô∏è‚É£ Hierarchy', '3Ô∏è‚É£ Filtering',
                  '4Ô∏è‚É£ Testing', '5Ô∏è‚É£ Visualization', '6Ô∏è‚É£ Reporting'],
        'Action': [
            'Load raw data with multiple price entries per project',
            'Aggregate prices by project, roll up to accounts',
            'Filter by Stage, Product, Year, Manager, etc.',
            'Statistical analysis on aggregated data',
            'Charts showing account and project breakdowns',
            'Export filtered and aggregated results'
        ]
    })

    st.dataframe(workflow_df, use_container_width=True)

    st.info("üëà **Get Started**: Load your SFDC data in Phase 1, then see hierarchy in Phase 2!")

# ============================================================================
# PHASE 1: DATA INGESTION  
# ============================================================================

elif phase == "üì• Phase 1: Data Ingestion":
    st.markdown("# üì• Phase 1: Data Ingestion")
    st.markdown("---")

    tab1, tab2, tab3 = st.tabs(["Upload File", "Sample Data", "Preview"])

    with tab1:
        st.markdown("### Upload Your SFDC Data")
        st.markdown("Supported formats: CSV, Excel, JSON, Parquet, TSV")
        uploaded_file = st.file_uploader("Choose a file", type=['csv', 'xlsx', 'xls', 'json', 'parquet', 'tsv'])

        if uploaded_file:
            loader = DataLoader()
            df, metadata = loader.load_from_upload(uploaded_file)

            if df is not None:
                st.session_state.data = df
                st.session_state.filtered_data = None
                st.session_state.aggregated_data = None
                st.success(f"‚úÖ Loaded: {df.shape[0]} rows √ó {df.shape[1]} columns")

    with tab2:
        st.markdown("### Load Sample Dataset")
        sample = st.selectbox("Choose sample:", ["None", "SFDC Sales Demo (with duplicates)"])

        if st.button("Load Sample"):
            if sample == "SFDC Sales Demo (with duplicates)":
                # Generate demo data with multiple prices per project
                np.random.seed(42)
                n_projects = 200
                n_total_rows = 600  # Multiple entries per project

                project_ids = [f'SFDC-{i:05d}' for i in range(n_projects)]
                years = [2020, 2021, 2022, 2023]
                stages = ['Won', 'Lost', 'Open', 'Closed']
                products = ['LSMS', 'Proteomics', 'Genomics', 'Clinical']
                accounts = [f'Account_{x}' for x in ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon']]
                managers = ['John', 'Jane', 'Bob', 'Alice', 'Charlie']

                # Create rows with duplicate projects
                rows = []
                for _ in range(n_total_rows):
                    project_id = np.random.choice(project_ids)
                    rows.append({
                        'SFDC Project No.': project_id,
                        'Accounts Name': np.random.choice(accounts),
                        'Current Account Manager': np.random.choice(managers),
                        'Product Line': np.random.choice(products),
                        'Total Price': np.random.randint(5000, 150000),  # Individual line items
                        'Close Year': pd.to_datetime(f'{np.random.choice(years)}-{np.random.randint(1,13):02d}-{np.random.randint(1,29):02d}'),
                        'Past Account Manager': np.random.choice(managers),
                        'Stage': np.random.choice(stages)
                    })

                st.session_state.data = pd.DataFrame(rows)
                st.session_state.aggregated_data = None
                st.success(f"‚úÖ SFDC demo loaded: {len(rows)} price entries for {n_projects} projects")

    with tab3:
        if st.session_state.data is not None:
            df = st.session_state.data
            st.markdown("### Data Preview (Raw Data)")
            st.dataframe(df.head(20), use_container_width=True)

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Rows", df.shape[0])
            with col2:
                st.metric("Columns", df.shape[1])
            with col3:
                if 'SFDC Project No.' in df.columns:
                    st.metric("Unique Projects", df['SFDC Project No.'].nunique())
            with col4:
                if 'Accounts Name' in df.columns:
                    st.metric("Unique Accounts", df['Accounts Name'].nunique())
        else:
            st.info("üëà Upload or load a dataset to see preview")

# ============================================================================
# PHASE 2: HIERARCHICAL ANALYSIS
# ============================================================================

elif phase == "üè¢ Phase 2: Hierarchical Analysis":
    st.markdown("# üè¢ Phase 2: Hierarchical Analysis")
    st.markdown("### Account > Project Aggregation")
    st.markdown("---")

    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please load data in Phase 1 first!")
    else:
        df = st.session_state.data

        # Detect columns
        project_col = None
        account_col = None
        price_col = None

        for col in df.columns:
            if 'project' in col.lower():
                project_col = col
            if 'account' in col.lower() and 'name' in col.lower():
                account_col = col
            if 'price' in col.lower() or 'revenue' in col.lower():
                price_col = col

        if not all([project_col, account_col, price_col]):
            st.error("‚ùå Could not detect required columns (Project, Account, Price)")
            st.info(f"Detected: Project={project_col}, Account={account_col}, Price={price_col}")
        else:
            # Create aggregator
            aggregator = HierarchicalAggregator(df)

            tab1, tab2, tab3 = st.tabs(["Account Level", "Project Level", "Drill-Down"])

            with tab1:
                st.markdown('<div class="hierarchy-header">üìä LEVEL 1: Account Summary</div>', unsafe_allow_html=True)

                if st.button("üîÑ Aggregate Data", key="agg_btn"):
                    # Step 1: Aggregate by project
                    project_agg = aggregator.aggregate_by_project(price_col, project_col)

                    # Step 2: Aggregate to account level
                    account_agg = aggregator.aggregate_by_account(price_col, account_col)

                    if account_agg is not None:
                        st.session_state.aggregated_data = account_agg
                        st.session_state.project_agg = project_agg
                        st.success(f"‚úÖ Aggregated {len(df)} rows ‚Üí {len(project_agg)} projects ‚Üí {len(account_agg)} accounts")

                if st.session_state.aggregated_data is not None:
                    account_agg = st.session_state.aggregated_data

                    # Display summary metrics
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Total Accounts", len(account_agg))
                    with col2:
                        st.metric("Total Revenue", f"${account_agg['Total_Revenue'].sum():,.0f}")
                    with col3:
                        st.metric("Avg per Account", f"${account_agg['Total_Revenue'].mean():,.0f}")
                    with col4:
                        st.metric("Total Projects", int(account_agg['Num_Projects'].sum()))

                    # Show top accounts
                    st.markdown("### üèÜ Top Accounts by Revenue")
                    top_accounts = account_agg.sort_values('Total_Revenue', ascending=False).head(10)

                    fig = px.bar(top_accounts, x=account_col, y='Total_Revenue',
                               title="Top 10 Accounts by Total Revenue",
                               labels={account_col: 'Account', 'Total_Revenue': 'Total Revenue ($)'})
                    st.plotly_chart(fig, use_container_width=True)

                    # Show full table
                    st.markdown("### üìã Account Summary Table")
                    st.dataframe(account_agg.sort_values('Total_Revenue', ascending=False), 
                               use_container_width=True)

            with tab2:
                st.markdown('<div class="hierarchy-header">üìÅ LEVEL 2: Project Aggregation</div>', unsafe_allow_html=True)

                if 'project_agg' in st.session_state and st.session_state.project_agg is not None:
                    project_agg = st.session_state.project_agg

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Total Projects", len(project_agg))
                    with col2:
                        st.metric("Total Revenue", f"${project_agg[price_col].sum():,.0f}")
                    with col3:
                        st.metric("Avg per Project", f"${project_agg[price_col].mean():,.0f}")

                    st.markdown("### üìã Project-Level Data (Aggregated)")
                    st.dataframe(project_agg.head(20), use_container_width=True)

                    # Top projects
                    st.markdown("### üèÜ Top 10 Projects by Value")
                    top_projects = project_agg.nlargest(10, price_col)
                    fig = px.bar(top_projects, x=project_col, y=price_col,
                               title="Top 10 Projects by Total Value")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("üëà Click 'Aggregate Data' in Account Level tab first")

            with tab3:
                st.markdown('<div class="hierarchy-header">üîç Account Drill-Down</div>', unsafe_allow_html=True)

                if 'project_agg' in st.session_state and st.session_state.project_agg is not None:
                    project_agg = st.session_state.project_agg

                    # Account selector
                    accounts = sorted(project_agg[account_col].unique())
                    selected_account = st.selectbox("Select Account to Drill Down:", accounts)

                    if selected_account:
                        # Get projects for this account
                        account_projects = aggregator.get_account_drill_down(selected_account)

                        if account_projects is not None and len(account_projects) > 0:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Projects", len(account_projects))
                            with col2:
                                st.metric("Total Revenue", f"${account_projects[price_col].sum():,.0f}")
                            with col3:
                                st.metric("Avg Project", f"${account_projects[price_col].mean():,.0f}")

                            st.markdown(f"### üìä Projects for {selected_account}")
                            st.dataframe(account_projects, use_container_width=True)

                            # Show breakdown by product line if available
                            if 'Product Line' in account_projects.columns:
                                product_summary = account_projects.groupby('Product Line')[price_col].sum().reset_index()
                                fig = px.pie(product_summary, values=price_col, names='Product Line',
                                           title=f"Revenue Breakdown by Product Line - {selected_account}")
                                st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("üëà Click 'Aggregate Data' in Account Level tab first")

# ============================================================================
# PHASE 3: ADVANCED FILTERING
# ============================================================================

elif phase == "üîç Phase 3: Advanced Filtering":
    st.markdown("# üîç Phase 3: Advanced Filtering")
    st.markdown("### Filter aggregated data by multiple criteria")
    st.markdown("---")

    # Use project-level aggregated data if available
    if 'project_agg' in st.session_state and st.session_state.project_agg is not None:
        df = st.session_state.project_agg
        st.info("‚ÑπÔ∏è Filtering project-level aggregated data")
    elif st.session_state.data is not None:
        df = st.session_state.data
        st.info("‚ÑπÔ∏è Filtering raw data (aggregate in Phase 2 first for better analysis)")
    else:
        st.warning("‚ö†Ô∏è Please load data in Phase 1 first!")
        df = None

    if df is not None:
        # Create filter section
        st.markdown('<div class="filter-box">', unsafe_allow_html=True)
        st.markdown("### üîç Multi-Criteria Filters")

        filter_cols = st.columns(3)
        filters = {}
        active_filters = []

        all_columns = df.columns.tolist()

        for idx, col in enumerate(all_columns):
            with filter_cols[idx % 3]:
                unique_vals = df[col].dropna().unique()

                if len(unique_vals) <= 50:
                    selected = st.multiselect(
                        f"üîπ {col}",
                        options=sorted(unique_vals.tolist(), key=str),
                        key=f"filter_{col}"
                    )
                    if selected:
                        filters[col] = selected
                        active_filters.append(f"{col} in {selected}")

                elif pd.api.types.is_numeric_dtype(df[col]):
                    min_val = float(df[col].min())
                    max_val = float(df[col].max())
                    range_vals = st.slider(
                        f"üîπ {col}",
                        min_val, max_val, (min_val, max_val),
                        key=f"filter_{col}"
                    )
                    if range_vals != (min_val, max_val):
                        filters[col] = range_vals
                        active_filters.append(f"{col} between {range_vals[0]:.0f} and {range_vals[1]:.0f}")

        st.markdown('</div>', unsafe_allow_html=True)

        col1, col2 = st.columns([1, 1])
        with col1:
            apply_button = st.button("üîç Apply Filters", type="primary", use_container_width=True)
        with col2:
            reset_button = st.button("üîÑ Reset", use_container_width=True)

        if reset_button:
            st.session_state.filtered_data = None
            st.rerun()

        if apply_button or filters:
            filtered_df = df.copy()

            for col, values in filters.items():
                if isinstance(values, list):
                    filtered_df = filtered_df[filtered_df[col].isin(values)]
                elif isinstance(values, tuple) and len(values) == 2:
                    if pd.api.types.is_numeric_dtype(df[col]):
                        filtered_df = filtered_df[(filtered_df[col] >= values[0]) & (filtered_df[col] <= values[1])]

            st.session_state.filtered_data = filtered_df

            if active_filters:
                st.markdown("### üéØ Active Filters")
                for i, f in enumerate(active_filters, 1):
                    st.markdown(f"**{i}.** {f}")

            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Original", f"{len(df):,}")
            with col2:
                st.metric("Filtered", f"{len(filtered_df):,}")
            with col3:
                pct = (len(filtered_df) / len(df)) * 100 if len(df) > 0 else 0
                st.metric("Match Rate", f"{pct:.1f}%")

            st.dataframe(filtered_df.head(20), use_container_width=True)

            # Export
            csv = filtered_df.to_csv(index=False)
            st.download_button(
                "üìÑ Download Filtered Data",
                csv,
                "filtered_data.csv",
                "text/csv"
            )

# Remaining phases remain the same...
# (Phase 4, 5, 6 similar to previous version but using aggregated data)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>Statistical Analysis Platform with Hierarchical Aggregation | Built with Streamlit</p>
</div>
""", unsafe_allow_html=True)
